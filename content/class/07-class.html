---
title: "Section 7: Deep Learning for Text"
# linktitle: "1. Introduction to RStudio and Images"
date: "2025-03-25"
class_date: "2025-03-25"
draft: false
output:
  blogdown::html_page:
    toc: false
menu:
  class:
    parent: Class sessions
    weight: 7
type: docs
weight: 1
# pdf: 
# thumb: 
editor_options: 
  chunk_output_type: console
---



<div id="deep-learning-for-text" class="section level3">
<h3>Deep Learning for Text</h3>
<p><a href="../../slides/ch11a_Text_encoding.html#1" target="_blank">Lecture slides in HTML format</a></p>
<iframe src="../../slides/ch11a_Text_encoding.html#1" width="672" height="400px" data-external="1">
</iframe>
<p><a href="../../slides/ch11b_Text_transformers.html#1" target="_blank">Lecture slides in HTML format</a></p>
<iframe src="../../slides/ch11b_Text_transformers.html#1" width="672" height="400px" data-external="1">
</iframe>
</div>
<div id="code" class="section level3">
<h3>Code</h3>
<ul>
<li>Text vectorization, embedding, <a href="../../slides/code/ch11_Text_encoding_code.Rmd">RMarkdown</a></li>
<li>Reusing Word2vec embeddings, <a href="../../slides/code/ch11_Text_word2vec_code.Rmd">RMarkdown</a></li>
<li>Attention math demo, <a href="../../slides/code/ch11_Text_attention_code.Rmd">RMarkdown</a></li>
<li>Transformed architecture, <a href="../../slides/code/ch11_Text_transformers_code.Rmd">RMarkdown</a>
<!-- - Transformer architecture in Keras, [RMarkdown](../../slides/code/ch11_Text_transformers_code.Rmd) -->
<!-- - word2vec demo, [Rmarkdown](../../slides/code/ch11_word2vec.Rmd) --></li>
</ul>
<!-- - [Daily Climate time series data](https://www.kaggle.com/datasets/sumanthvrao/daily-climate-time-series-data) -->
<!-- - [Netflix | Stock Market Analysis | Founding Years](https://www.kaggle.com/datasets/whenamancodes/netflix-stock-market-analysis-founding-years) -->
<!-- - [Airbnb, Inc. Stock Market Analysis](https://www.kaggle.com/datasets/whenamancodes/airbnb-inc-stock-market-analysis) -->
<!-- - [META | Stock Market Analysis | Founding Years](https://www.kaggle.com/datasets/whenamancodes/meta-stock-market-analysis-founding-years) -->
<!-- - [TESLA Inc | Stock Market Analysis | Founding Years](https://www.kaggle.com/datasets/whenamancodes/tesla-inc-stock-market-analysis-founding-years) -->
<!-- - [Dogecoin Historical Data](https://www.kaggle.com/datasets/dhruvildave/dogecoin-historical-data) -->
</div>
<div id="references" class="section level3">
<h3>References</h3>
<ul>
<li><a href="https://text2vec.org/vectorization.html">Text analysis pipeline</a> - text2vec tutorials</li>
<li><a href="https://towardsdatascience.com/nlp-illustrated-part-3-word2vec-5b2e12b6a63b/">NLP Illustrated, Part 3: Word2Vec</a> - word2vec illustrated guide</li>
<li>Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, and Illia Polosukhin. “Attention is all you need.” Advances in neural information processing systems 30 (2017). <a href="https://arxiv.org/abs/1706.03762" class="uri">https://arxiv.org/abs/1706.03762</a></li>
</ul>
<!-- - [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) -->
</div>
