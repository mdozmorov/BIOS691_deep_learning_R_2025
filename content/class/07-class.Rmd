---
title: "Section 7: Deep Learning for Text"
# linktitle: "1. Introduction to RStudio and Images"
date: "2025-03-25"
class_date: "2025-03-25"
draft: false
output:
  blogdown::html_page:
    toc: false
menu:
  class:
    parent: Class sessions
    weight: 7
type: docs
weight: 1
# pdf: 
# thumb: 
editor_options: 
  chunk_output_type: console
---

### Deep Learning for Text

<a href="../../slides/ch11a_Text_encoding.html#1" target="_blank">Lecture slides in HTML format</a>

```{r echo=FALSE}
knitr::include_url('../../slides/ch11a_Text_encoding.html#1')
```

<a href="../../slides/ch11b_Text_transformers.html#1" target="_blank">Lecture slides in HTML format</a>

```{r echo=FALSE}
knitr::include_url('../../slides/ch11b_Text_transformers.html#1')
```

### Code

- Text vectorization, embedding, [RMarkdown](../../slides/code/ch11_Text_encoding_code.Rmd)
- Reusing Word2vec embeddings, [RMarkdown](../../slides/code/ch11_Text_word2vec_code.Rmd)
- Attention math demo, [RMarkdown](../../slides/code/ch11_Text_attention_code.Rmd)
- Transformed architecture, [RMarkdown](../../slides/code/ch11_Text_transformers_code.Rmd)
<!-- - Transformer architecture in Keras, [RMarkdown](../../slides/code/ch11_Text_transformers_code.Rmd) -->
<!-- - word2vec demo, [Rmarkdown](../../slides/code/ch11_word2vec.Rmd) -->

<!-- - [Daily Climate time series data](https://www.kaggle.com/datasets/sumanthvrao/daily-climate-time-series-data) -->

<!-- - [Netflix | Stock Market Analysis | Founding Years](https://www.kaggle.com/datasets/whenamancodes/netflix-stock-market-analysis-founding-years) -->

<!-- - [Airbnb, Inc. Stock Market Analysis](https://www.kaggle.com/datasets/whenamancodes/airbnb-inc-stock-market-analysis) -->
<!-- - [META | Stock Market Analysis | Founding Years](https://www.kaggle.com/datasets/whenamancodes/meta-stock-market-analysis-founding-years) -->
<!-- - [TESLA Inc | Stock Market Analysis | Founding Years](https://www.kaggle.com/datasets/whenamancodes/tesla-inc-stock-market-analysis-founding-years) -->
<!-- - [Dogecoin Historical Data](https://www.kaggle.com/datasets/dhruvildave/dogecoin-historical-data) -->

### References

- [Text analysis pipeline](https://text2vec.org/vectorization.html) - text2vec tutorials
- [NLP Illustrated, Part 3: Word2Vec](https://towardsdatascience.com/nlp-illustrated-part-3-word2vec-5b2e12b6a63b/) - word2vec illustrated guide
- Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, ≈Åukasz Kaiser, and Illia Polosukhin. "Attention is all you need." Advances in neural information processing systems 30 (2017). https://arxiv.org/abs/1706.03762
- [LLMs-from-scratch](https://github.com/rasbt/LLMs-from-scratch) - Implement a ChatGPT-like LLM in PyTorch from scratch, step by step. [Youtube playlist](https://youtube.com/playlist?list=PLTKMiZHVd_2IIEsoJrWACkIxLRdfMlw11)

<!--
Temperature prediction with Transformers. 
- Use the Jena dataset from the "Deep Learning for Time Series" section 6 (https://bios691-deep-learning-r-2025.netlify.app/slides/code/ch10_RNN_code.Rmd). For simplicity, subset it to have one measurement per hour. 
- Use RNN, LSTM (GRU), and their bidirectional variants to predict temperature 24 h in the future. Note this is a regression problem.
- Use 1 day, 2 days, 7 days measurements for prediction (window size).
- Use Transformer encoder architecture to capture positional representation of measurements followed by either a dense layer, or an RNN/LSTM layer before the output layer. 
- Summarize performance (accuracy/loss plots, best performance on the unseen data) of each architecture and window size in a table. Answer the following questions:
  - How well RNN/LSTM or Transformer layers alone perform?
  - Does the bidirectional wrapper help?
  - Can the RNN/LSTM performance be improved if provided with the Transformer encoder output?
- Bonus (to get 10 points: Use Convolutional 1D architecture, alone and using the Transformer encoder output.
- Hint: Consider the "Timeseries classification with a Transformer model" example, https://tensorflow.rstudio.com/examples/timeseries_classification_transformer
- Submit the knitted HTML and the Rmd code. Make efforts to organize/comment your code and the final report.
-->

<!-- - [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) -->